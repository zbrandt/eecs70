\documentclass[11pt]{article}
\usepackage{header}
\def\title{HW 08}

\begin{document}
\maketitle
\fontsize{12}{15}\selectfont

\begin{center}
    Due: Saturday, 3/22, 4:00 PM \\
    Grace period until Saturday, 3/22, 6:00 PM \\
\end{center}

\section*{Sundry}
Before you start writing your final homework submission, state briefly how you worked on it.  Who else did you work with?  List names and email addresses.  (In case of homework party, you can just describe the group.)

\begin{center}
    \textcolor{blue}{
        Zachary Brandt \\
        \nolinkurl{zbrandt@berkeley.edu}
    }
\end{center}

\vspace{15pt}

\Question{Unprogrammable Programs}

\notelinks{\href{https://www.eecs70.org/assets/pdf/notes/n12.pdf}{Note 12}}
Prove whether the programs described below can exist or not.

\begin{Parts}

\Part A program $P(F,x,y)$ that returns true if the program $F$ outputs $y$ when given $x$ as input (i.e. $F(x)=y$) and false otherwise.

\Part A program $P$ that takes two programs $F$ and $G$ as arguments, and returns true if for all inputs $x$, $F$ halts on $x$ iff $G$ halts on $x$ (and returns false if this equivalence is not always true).

\textit{Hint:} Use $P$ to solve the halting problem, and consider defining two subroutines to pass in to $P$, where one of the subroutines always loops.

\end{Parts}

\begin{solution}

\begin{Parts}
\Part To solve this problem, assume that the program $P(F,x,y)$ does exist, which allows
for solving the Halting problem, which cannot be solved, i.e., there is a contradiction and
therefore the assumption, that $P(F,x,y)$ exists, is false. With $P$ we can solve the Halting
problem as follows:

\begin{lstlisting}[language=Python]
def TestHalt(H, x):
    def Q(x):
        run H(x)
        return 1
    return P(Q, x, 1)
\end{lstlisting}

If $P$ exists, it can determine if $Q$ halts, because if it does return 1, then it halts, and
if it doesn't return $1$ then $Q$ must run forever. 

\Part I will use the same approach as before to show that this $P$ does not exist. 

\begin{lstlisting}[language=Python]
def TestHalt(H, x):
    def F(a):
        if a == x:
            while True:
                print('Hello World')
        else:
            return H(a)
    return not P(H, F)
\end{lstlisting}

In this program, if $H$ does not halt on an input $x$, then $P(H, F)$ will return true, solving
the Halting problem. This is because $F$ checks for this input, and if it detects it, it will
also loop, by printing ``Hello World'' until the end of time. If $H$ does halt on an input $x$,
then $F$ and $H$ will not have the same behavior on all inputs, and $P$ will return false, which,
with the `not', will tell TestHalt that $H$ does halt. Since this function $P$ solves the Halting
problem, we have derived our contradiction, since the Halting problem cannot be solved, and the
program $P$ cannot exist. 

\end{Parts}

\end{solution}

\Question{Kolmogorov Complexity}

\notelinks{\href{https://www.eecs70.org/assets/pdf/notes/n12.pdf}{Note 12}}
Compressing a bit string $x$ of length $n$ can be interpreted as the task of creating a program of fewer than $n$ bits that returns $x$.
The Kolmogorov complexity of a string $K(x)$ is the length of an optimally-compressed copy of $x$; that is, $K(x)$ is the length of shortest program that returns $x$.

\begin{Parts}

\Part
Explain why the notion of the "smallest positive integer that cannot be defined in under 280 characters" is paradoxical.

\Part
Prove that for any length $n$, there is at least one string of bits that cannot be compressed to less than $n$ bits, assuming that no two strings can be compressed to the same value.

\Part
Say you have a program $K$ that outputs the Kolmogorov complexity of any input
string. Under the assumption that you can use such a program $K$ as a
subroutine, design another program $P$ that takes an integer $n$ as input, and
outputs the length-$n$ binary string with the highest Kolmogorov complexity. If
there is more than one string with the highest complexity, output the one that
comes first lexicographically.

\Part
Let's say you compile the program $P$ you just wrote and get an $m$ bit
executable, for some $m \in \mathbb N$ (i.e. the program $P$ can be represented
in $m$ bits). Prove that the program $P$ (and consequently the program $K$)
cannot exist.

(\textit{Hint}: Consider what happens when $P$ is given a very large input $n$ that is much greater than $m$.)

\end{Parts}

\begin{solution}

\begin{Parts}
\Part The statement defines some integer $n$ that cannot be defined in under 280
characters. However, this statement itself is under 280 characters. If some integer
with this property existed, then it is possible to definite it in under 280 
characters, as it is done here (in 72 characters). That is, it is self-contradicting
and a paradox.

\Part This can be proven with the Pidgeon Hole principle, because there are more
$n$-length bit strings than there are less-than-$n$-length bit strings. There are
$2^n$ $n$-length bit strings, but there are only 
\[
    2^{n-1} +2^{n-2} + \dots + 2^1 + 2^0 = 2^n-1
\]
bit strings of length less than $n$. Therefore, at least one bit string of length
$n$ cannot be compressed to one of length less than $n$.

\Part 

\begin{lstlisting}[language=Python]
def P(n):
    big = -infinity
    best = None
    for i in range(0 to 2**n):
        str = n_length_bit_string(i)
        if K(x) >= big:
            big = K(x)
            best = x 
    return best
\end{lstlisting}

This is supposed to be a Python pseudocode function, and the range function is exclusive for $2^n$.
This program finds the highest Kolmogrov complexity string of length $n$ by checking
over all possible length $n$ bit strings since there are only so many of them. 

\Part When $P$ is given a large input $n$ much greater than $m$, $K(P(n)) > n > m$.
This is because there must exist a binary string of length $n$ that cannot be compressed
to a length less than $n$ (from before with the Pidgeon Hole principle). $P(n)$ will 
find this incompressible string, because it checks all $n$ length strings and returns
the one with the highest Komolgrov complexity. Then, $K(P(n))$ gets that Komolgrov
complexity. 

But since
there exists an $m$ bit executable from the compilation of $P$ from the prompt, that means
there is a length $m$ bit string that can produce $P(n)$, i.e. $K(P(n)) = m$. But since
we just showed that $K(P(n)) > m$, this leads to a contradiction. Therefore, $P$ cannot
exist and since it relies on $K$, $K$ also does not exist. 

\end{Parts}

\end{solution}

\Question{Five Up}

\notelinks{\href{https://www.eecs70.org/assets/pdf/notes/n13.pdf}{Note 13}}
Say you toss a coin five times, and record the outcomes. For the three questions
below, you can assume that order matters in the outcome, and that the
probability of heads is some $p$ in $0 < p < 1$, but \textit{not} that the coin
is fair ($p = 0.5$).

\begin{Parts}
\Part What is the size of the sample space, $|\Omega|$?

\Part How many elements of $\Omega$ have exactly three heads?

\Part How many elements of $\Omega$ have three or more heads?
\end{Parts}

For the next three questions, you can assume that the coin is fair (i.e. heads 
comes up with $p=0.5$, and tails otherwise).

\begin{Parts}[resume]
\Part What is the probability that you will observe the sequence HHHTT? What 
about HHHHT?

\Part What is the probability of observing at least one head?

\Part What is the probability you will observe more heads than tails?

\end{Parts}

\begin{solution}

\begin{Parts}
\Part The size of the sample space $\Omega$ is $2^5=32$. Elements in the sample
space are of the type $\omega \in \mathbb{R}^5$.

\Part For three heads out of five coin flips, this subset of $\Omega$ has size
$\binom{5}{3}=10$.

\Part This subset is the union of the subsets of eleemnts with only 3, 4, and 5
heads each, i.e., $\binom{5}{3} + \binom{5}{4} + \binom{5}{5} = 10 + 5 + 1 = 16$.

\Part For both sequences, the probability of observing each is $\frac{1}{2^5} =
\frac{1}{32}$.

\Part The complement of the subset of elements with at least one head is the 
subset of elements containing no heads. Therefore, the probability of observing
a sequence with at least one head is $1 - \frac{1}{32} = \frac{31}{32}$, since
there is only one sequence without any heads (TTTTT).

\Part For there to be more heads than tails, there must be at most two tails
in the sequence. The number of elements with this property is $\binom{5}{0}
+ \binom{5}{1} + \binom{5}{2} = 10 + 5 + 1 = 16$. The probability of 
observing such a sequence is then $\frac{16}{32} = \frac{1}{2}$.

\end{Parts}

\end{solution}

\Question{Aces}

\notelinks{\href{https://www.eecs70.org/assets/pdf/notes/n13.pdf}{Note 13}}
Consider a standard 52-card deck of cards, which has 4 suits (hearts, diamonds,
clubs, and spades) with 13 cards in each suit. Each suit has one ace. Hearts 
and diamonds are red, while clubs and spades are black. 
\begin{Parts}
    \Part Find the probability of getting an ace or a red card, when drawing a 
    single card.
    
    \Part Find the probability of getting an ace or a spade, but not both, when 
    drawing a single card.
    
    \Part Find the probability of getting the ace of diamonds when drawing a 5 
    card hand.
    
    \Part Find the probability of getting exactly 2 aces when drawing a 5 card 
    hand.
    
    \Part Find the probability of getting at least 1 ace when drawing a 5 card 
    hand.
    
    \Part Find the probability of getting at least 1 ace or at least 1 heart when 
    drawing a 5 card hand.
    
\end{Parts}

\begin{solution}

\begin{Parts}
\Part There are four aces and 26 red cards in a 52-card deck, but two of the red
cards is an ace, therefore $\frac{4 + 26 - 2}{52} = \frac{28}{52}$ is the 
probability of drawing a single ace or red card. 

\Part There are four aces and one of them is the ace of spades. There are 12 
other cards that are spades. Therefore, $\frac{3 + 12}{52} = \frac{15}{52}$
is the probability.

\Part The complement of the subset of 5 card hands that contain the ace of 
diamonds is the subset of 5 card hands not containing the ace of diamonds, 
which is of size $\binom{51}{5}$. Therefore, the probability is $1 - 
\binom{51}{5} \div \binom{52}{5}$. 

\Part There are $\binom{4}{2} \times \binom{48}{3}$ 5-card hands with exactly 2 
of the aces (first choose the two, then choose the remaining cards). Therefore,
the probability of drawing such a hand is $\left( \binom{4}{2} \binom{48}{3}
\right) \div \binom{52}{5}$. 

\Part The complement of the subset of 5-card hands with at least one ace is the
subset of hands containing no aces, which is of size $\binom{48}{5}$. Therefore,
the probability is $1 - \binom{48}{5} \div \binom{52}{5}$.

\Part The complement of this subset is subset of 5-card hands containing no aces
and no hearts, which is of size $\binom{52 - 4 - 13 + 1}{5} = \binom{36}{5}$.
Therefore, the probability is $1 - \binom{36}{5} \div \binom{52}{5}$.

\end{Parts}

\end{solution}

\Question{Past Probabilified}
\notelinks{\href{https://www.eecs70.org/assets/pdf/notes/n13.pdf}{Note 13}}
In this question we review some of the past CS70 topics, and look at them 
probabilistically.
\\ 
For the following experiments, define an appropriate sample space $\Omega$, and
give the probability function $\mathbb P[\omega]$ for each $\omega \in \Omega$. 
Then compute the probabilities of the events $E_1$ and $E_2$. 
\\

\begin{Parts}
    \Part Fix a prime $p>2$, and uniformly sample twice with replacement from
    $\{0, \dots, p-1\}$ (assume we have two $\{0, \dots, p-1\}$-sided fair dice 
    and we roll them). Then multiply these two numbers with each other in
    $(\bmod{p})$ space.\\
    \begin{center}
    $E_1 =$ The resulting product is $0$.\\
    $E_2 =$ The product is $(p-1)/2$.
    \end{center}

    \Part Make a graph on $n$ vertices by sampling uniformly at random from all 
    possible edges, (assume for each edge we flip a coin and if it is head we 
    include the edge in the graph and otherwise we exclude that edge from the 
    graph).
    \\
    \begin{center}
    $E_1 =$ The graph is complete.\\
    $E_2 =$ vertex $v_1$ has degree $d$.
    \end{center}

    \Part Create a random stable matching instance by having each person's
    preference list be a random permutation of the opposite entity's list (make 
    the preference list for each individual job and each individual candidate a 
    random permutation of the opposite entity's list). Finally, create a uniformly 
    random pairing by matching jobs and candidates up uniformly at random (note 
    that in this pairing, (1) a candidate cannot be matched with two different 
    jobs, and a job cannot be matched with two different candidates (2) the 
    pairing does not have to be stable).
    \\
    \begin{center}
     $E_1 =$ All jobs have distinct favorite candidates.\\
     $E_2 =$ The resulting pairing is the candidate optimal stable pairing.
    \end{center}

\end{Parts}

\begin{solution}

\begin{Parts}
\Part The sample space for this question is $\Omega = \{ (0, 0), \dots, (p-1, p-1)
\}$ with size $|\Omega| = p^2$ where the elements are $\omega \in \mathbb{R}^2$
and represent all the possible pairs, e.g., of the dice rolls. The probability for
any $\omega$ is $\mathbb{P}[\omega] = \frac{1}{p^2}$. For the product of the two
numbers to be zero under modulos $p$, the product must be a multiple of $p$. 
This only happens when at least one of the two numbers is zero, which is the case
for $p + p - 1$ pairs ($p$ pairs where the first number is zero, $p$ pairs where
the second number is zero, -1 for double counting the double-zero pair). Therefore,
the probability of $E_1$ is $\mathbb{P}[E_1] = \frac{2p-1}{p^2}$. For the product
of two numbers to equal $(p-1)/2$, neither the first or second dice rolls can be
zero. 
\[
    \begin{split}
        x_1 \times x_2 \equiv \frac{p-1}{2} &\pmod{p} \\
        x_1 \equiv x_2^{-1} \times \frac{p-1}{2} &\pmod{p}
    \end{split}
\]
Since for every value $x_2$ in $\{ 1, 2, \dots, p-1 \}$ the greatest common
with $p$ will be 1, since $p$ is prime, there will be an $x_1$ that
satisfies the above equivalency. Therefore, there are $p-1$ such values (because
0 is excluded), and the probability of $E_2$ is $\mathbb{P}[E_2] = \frac{p-1}{p^2}$.

\Part The sample space for this question is all possible $\binom{n}{2}$-length 
sequences of ones and zeros that define the edges of a graph (the first one
could represent there being an edge between the first and second labeled vertices,
for example). The size of this sample space is $|\Omega| = 2^{\binom{n}{2}}$, 
since there are $n$ choose 2 possible edges and it can either exist or not. The
probability of observing a given sequence $\omega \in \Omega$ is $\mathbb{P}[\omega]=
\frac{1}{2^{\binom{n}{2}}}$. The probability of observing $E_1$ is also exactly
this probability, because there is only one element in the sample space where
all edges are connected, i.e., $\mathbb{P}[E_1] = 1 \div 2^{\binom{n}{2}}$. If
vertex $v_1$ has some given degree $d$, we now only consider $n-1$ other vertices
for this graph. So, there are $\binom{n-1}{d} \times 2^{\binom{n-1}{2}}$ graphs 
with this configuration (first choose which edges make the $v_1$ degree $d$,
then consider the rest of the graph's edges). Therefore, the probability of 
observing $E_2$ is 
\[
    \mathbb{P}[E_2]=\frac{\binom{n-1}{d} \times 2^{\binom{n-1}{2}}}{2^{\binom{n}{2}}}.
\]

\Part If there are both $n$ jobs and $n$ candidates, there are $n!$ possible orderings
of each person's preferences of candidates or jobs. Since there are $2n$ people in total,
there are $(n!)^{2n}$ ways to construct all the preferences lists. For each one of these
ways, there are $n!$ different pairings (not all necessarily stable), since for the first
job there are $n$ candidates to pick from, for the second then $n-1$, and so on. The sample
space $\Omega$ of all possible pairings is then of size $|\Omega|= (n!)^{2n}\times n! = 
(n!)^{2n+1}$. The probability of observing any one $\omega$ of these pairings is then 
$\mathbb{P}[\omega]=\frac{1}{(n!)^{2n+1}}$. $E_1$ concerns itself with the preferences of
the jobs. The first job has $n!$ possible orderings. The second job has $n-1$ candidates
to pick from for its favorite candidate now (since the first job already made its choice),
and there are $(n-1)!$ orderings for the remaining jobs. The third job then has $n-2$ choices
to make for its favorite and still $(n-1)!$ orderings for the remaining. Therefore, the total
number of ways to construct all job preference lists is $n(n-1)! \times (n-1)(n-1)! \times 
(n-2)(n-1)!\times \dots \times (1)(n-1)! = ((n-1)!)^n\times n!$. The size of the subset of 
pairings with such job preference is then $n!\times((n-1)!)^n \times (n!)^n \times n!$, and the
probability of $E_1$ is 
\[
    \begin{split}
        \mathbb{P}[E_1] &= \frac{n!\times((n-1)!)^n \times (n!)^n \times n!}{(n!)^{2n+1}} \\
        &= \frac{n!\times((n-1)!)^n}{(n!)^n} \\
        &= \frac{n!\times((n-1)!)^n}{(n!)^n} \\
        &= \frac{((n-1)!)^n}{(n!)^{n-1}} \\
        &= \frac{(n-1)!}{(n)^{n-1}} \\
        &= \frac{n!}{n^{n}}
    \end{split}
\]

There is only one candidate-optimal pairing for any set of preference lists, therefore the
probability of $E_2$ is $\mathbb{P}[E_2]=\frac{(n!)^{2n}}{(n!)^{2n+1}} = \frac{1}{n!}$.


\end{Parts}

\end{solution}

\end{document}
